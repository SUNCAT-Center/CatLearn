{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborlist Feature Generators <a name=\"head\"></a>\n",
    "\n",
    "In this tutorial, we will look at generating features from a database of organic donor-acceptor molecules from the [Computational Materials Repository](https://cmrdb.fysik.dtu.dk/?project=solar). This has been downloaded in the [ase-db](https://wiki.fysik.dtu.dk/ase/ase/db/db.html#module-ase.db) format so first off we load the atoms objects and get a target property. Then we convert the atoms objects into a feature array and test out a couple of different models.\n",
    "\n",
    "This tutorial will give an indication of one way in which it is possible to handle atoms objects of different sizes. In particular, we focus on a feature set that scales with the number of atoms. We pad the feature vectors to a constant size to overcome this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out this line when exported to .py file\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.font_manager as font_manager\n",
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "import seaborn as sns\n",
    "\n",
    "import ase.db\n",
    "\n",
    "from catlearn.featurize.setup import FeatureGenerator\n",
    "from catlearn.regression import RidgeRegression, GaussianProcess\n",
    "from catlearn.cross_validation import Hierarchy\n",
    "from catlearn.regression.cost_function import get_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have stored our atomic structures in an ASE database file. Therefore, we first need to import it and put it in a list of atoms objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the ase-db.\n",
    "db = ase.db.connect('../../data/solar.db')\n",
    "atoms = list(db.select())\n",
    "random.shuffle(atoms)\n",
    "\n",
    "# Compile a list of atoms and target values.\n",
    "alist = []\n",
    "targets = []\n",
    "for row in atoms:\n",
    "    try:\n",
    "        targets.append(row.Energy)\n",
    "        alist.append(row.toatoms())\n",
    "    except AttributeError:\n",
    "        continue\n",
    "print('pulled {} molecules from db'.format(len(alist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the size of molecules in the db.\n",
    "size = []\n",
    "for a in alist:\n",
    "    size.append(len(a))\n",
    "\n",
    "print('min: {0}, mean: {1:.0f}, max: {2} molecule size'.format(\n",
    "    min(size), sum(size)/len(size), max(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide up the data into a test and training set.\n",
    "train_size = 1000\n",
    "train_atoms = alist[:train_size]\n",
    "test_atoms = alist[train_size:]\n",
    "train_targets = np.asarray(targets[:train_size])\n",
    "test_targets = np.asarray(targets[train_size:])\n",
    "\n",
    "print('{} shape training atoms data'.format(\n",
    "    np.shape(train_atoms)))\n",
    "print('{} shape testing atoms data'.format(\n",
    "    np.shape(test_atoms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = FeatureGenerator(element_parameters=['atomic_number'])\n",
    "\n",
    "generator.normalize_features(\n",
    "    train_candidates=train_atoms, test_candidates=test_atoms)\n",
    "print('Max number of atom present in data: {}'.format(generator.atom_len))\n",
    "print('Atom numbers present in data: {}'.format(generator.atom_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = generator.return_vec(\n",
    "    train_atoms, [generator.neighbor_sum_vec])\n",
    "\n",
    "test_features = generator.return_vec(\n",
    "    test_atoms, [generator.neighbor_sum_vec])\n",
    "\n",
    "print('{} shape training feature matrix'.format(\n",
    "    np.shape(train_features)))\n",
    "print('{} shape testing feature matrix'.format(\n",
    "    np.shape(test_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = np.max(train_features, axis=0) - np.min(train_features, axis=0)\n",
    "np.place(dif, dif == 0., [1.])\n",
    "mean = np.mean(train_features, axis=0)\n",
    "scaled = (train_features.copy() - mean) / dif\n",
    "plt.figure(num=0, figsize=(30,15))\n",
    "cmap = sns.diverging_palette(250, 15, s=75, l=40, n=1000, center=\"dark\")\n",
    "sns.heatmap(scaled, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = (test_features.copy() - mean) / dif\n",
    "plt.figure(num=1, figsize=(30,15))\n",
    "cmap = sns.diverging_palette(250, 15, s=75, l=40, n=1000, center=\"dark\")\n",
    "sns.heatmap(scaled, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = train_features.copy()\n",
    "td = np.reshape(train_targets.copy(), (len(train_targets), 1))\n",
    "train_data = np.concatenate((tf, td), axis=1)\n",
    "\n",
    "columns = ['f{}'.format(i) for i in range(np.shape(train_features)[1])]\n",
    "columns += ['target']\n",
    "index = range(np.shape(train_features)[0])\n",
    "df = pd.DataFrame(train_data, index=index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap('Spectral')\n",
    "\n",
    "def parallel_plot(data, num=None):\n",
    "    plt.figure(num=num, figsize=(50,25))\n",
    "    ax = parallel_coordinates(\n",
    "        data, 'target', colormap=cmap, axvlines=False)\n",
    "\n",
    "    plt.legend().set_visible(False)\n",
    "    plt.grid(False)\n",
    "\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontname('Arial')\n",
    "        label.set_fontsize(0)\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontname('Arial')\n",
    "        label.set_fontsize(30)\n",
    "    axis_font = {'fontname':'Arial', 'size':'35'}\n",
    "    plt.ylabel(\"Numeric Representation\", **axis_font)\n",
    "    plt.xlabel(\"Fingerprint\", **axis_font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_plot(df, num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = (df - df.mean()) / (df.max() - df.min())\n",
    "df_norm.fillna(0.)\n",
    "parallel_plot(df_norm, num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = (df - df.mean()) / df.std()\n",
    "df_std.fillna(0.)\n",
    "parallel_plot(df_std, num=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the ridge regression function.\n",
    "rr = RidgeRegression(W2=None, Vh=None, cv='loocv')\n",
    "b = rr.find_optimal_regularization(X=train_features, Y=train_targets)\n",
    "coef = rr.RR(X=train_features, Y=train_targets, omega2=b)[0]\n",
    "\n",
    "# Test the model.\n",
    "sumd = 0.\n",
    "err = []\n",
    "pred = []\n",
    "for tf, tt in zip(test_features, test_targets):\n",
    "    p = np.dot(coef, tf)\n",
    "    pred.append(p)\n",
    "    sumd += (p - tt) ** 2\n",
    "    e = ((p - tt) ** 2) ** 0.5\n",
    "    err.append(e)\n",
    "error = (sumd / len(test_features)) ** 0.5\n",
    "\n",
    "print(error)\n",
    "plt.figure(num=5)\n",
    "plt.figure(figsize=(30, 15))\n",
    "plt.plot(test_targets, pred, 'o', c='b', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdict = [\n",
    "    {\n",
    "        'type': 'gaussian', 'width': 1., 'scaling': 1., 'dimension': 'single'},\n",
    "    {\n",
    "        'type': 'linear', 'scaling': 1.},\n",
    "    ]\n",
    "gp = GaussianProcess(train_fp=train_features, train_target=train_targets,\n",
    "                     kernel_list=kdict, regularization=1e-2,\n",
    "                     optimize_hyperparameters=True, scale_data=True)\n",
    "\n",
    "pred = gp.predict(test_fp=test_features)\n",
    "\n",
    "error = get_error(pred['prediction'],\n",
    "                  test_targets)['rmse_average']\n",
    "\n",
    "print(error)\n",
    "plt.figure(num=6)\n",
    "plt.figure(figsize=(30, 15))\n",
    "plt.plot(test_targets, pred['prediction'], 'o', c='r', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
